2023-04-17T20:39:04,459 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T20:39:04,459 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T20:39:04,657 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T20:39:04,657 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T20:39:04,666 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T20:39:04,666 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T20:39:04,682 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T20:39:04,682 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T20:39:05,719 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T20:39:05,719 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T20:39:05,720 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T20:39:05,720 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T20:39:05,720 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T20:39:05,720 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T20:39:05,720 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T20:39:05,720 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T20:39:05,726 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:05,726 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:05,729 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T20:39:05,729 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T20:39:05,775 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T20:39:05,775 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T20:39:05,775 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T20:39:05,775 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T20:39:05,776 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T20:39:05,776 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T20:39:05,776 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T20:39:05,776 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T20:39:05,777 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T20:39:05,777 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T20:39:06,006 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T20:39:06,006 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T20:39:06,776 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,777 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.675048828125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,777 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.49181365966797|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,777 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,778 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:60.44921875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,778 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1238|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,778 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,778 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:22240.9609375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,778 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2955.234375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:06,779 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:13.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681778346
2023-04-17T20:39:07,348 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T20:39:07,350 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T20:39:07,351 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]3745
2023-04-17T20:39:07,351 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T20:39:07,351 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T20:39:07,351 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T20:39:07,351 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T20:39:07,354 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:07,354 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:07,358 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T20:39:07,359 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778347359
2023-04-17T20:39:07,359 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778347359
2023-04-17T20:39:07,373 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T20:39:09,543 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T20:39:09,543 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T20:39:09,544 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T20:39:09,544 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:09,544 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T20:39:09,544 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:09,544 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T20:39:09,544 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:09,544 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:09,544 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T20:39:09,545 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T20:39:09,545 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T20:39:09,546 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T20:39:09,546 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T20:39:09,546 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T20:39:09,546 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T20:39:09,546 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T20:39:09,546 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/2e30ba9a411d478abd2d43c7372ab39f/tshandler.py", line 29, in initialize
2023-04-17T20:39:09,547 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from server.mask import mask_setup
2023-04-17T20:39:09,547 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/2e30ba9a411d478abd2d43c7372ab39f/server/mask.py", line 8, in <module>
2023-04-17T20:39:09,547 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from .get_mask.test import *
2023-04-17T20:39:09,547 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/2e30ba9a411d478abd2d43c7372ab39f/server/get_mask/test.py", line 30, in <module>
2023-04-17T20:39:09,547 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from .utils.pyvotkit.region import vot_overlap, vot_float2str
2023-04-17T20:39:09,547 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/2e30ba9a411d478abd2d43c7372ab39f/server/get_mask/utils/pyvotkit/__init__.py", line 9, in <module>
2023-04-17T20:39:09,548 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from . import region
2023-04-17T20:39:09,548 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ImportError: cannot import name 'region' from partially initialized module 'server.get_mask.utils.pyvotkit' (most likely due to a circular import) (/tmp/models/2e30ba9a411d478abd2d43c7372ab39f/server/get_mask/utils/pyvotkit/__init__.py)
2023-04-17T20:39:09,545 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:09,545 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:09,553 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:09,553 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:09,553 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:09,553 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:09,553 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:09,553 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:09,553 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:09,553 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:09,553 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T20:39:09,553 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T20:39:09,561 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:09,561 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:09,561 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:09,561 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:10,554 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:10,554 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:11,266 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T20:39:11,268 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T20:39:11,268 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]3814
2023-04-17T20:39:11,268 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T20:39:11,268 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T20:39:11,268 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T20:39:11,269 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:11,269 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T20:39:11,269 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:11,269 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T20:39:11,270 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778351270
2023-04-17T20:39:11,270 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778351270
2023-04-17T20:39:11,275 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T20:39:13,080 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T20:39:13,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T20:39:13,081 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:13,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T20:39:13,081 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:13,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T20:39:13,081 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:13,081 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:13,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T20:39:13,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T20:39:13,081 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:13,081 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T20:39:13,082 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:13,082 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:13,082 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:13,082 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:13,082 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:13,082 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T20:39:13,082 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:13,082 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T20:39:13,082 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:13,091 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:13,091 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:14,083 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:14,083 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:14,785 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T20:39:14,787 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T20:39:14,788 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]3851
2023-04-17T20:39:14,788 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T20:39:14,788 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T20:39:14,788 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T20:39:14,788 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T20:39:14,788 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:14,788 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:14,789 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778354789
2023-04-17T20:39:14,789 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778354789
2023-04-17T20:39:14,789 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T20:39:14,795 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T20:39:16,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T20:39:16,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T20:39:16,580 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:16,580 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:16,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T20:39:16,580 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:16,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T20:39:16,580 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:16,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T20:39:16,580 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:16,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T20:39:16,580 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:16,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T20:39:16,581 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:16,581 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:16,581 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:16,581 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:16,581 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:16,581 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:16,581 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:16,581 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:16,581 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T20:39:16,581 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T20:39:16,582 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T20:39:16,582 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:16,582 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:16,589 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:16,589 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:18,582 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:18,582 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T20:39:19,281 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T20:39:19,283 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T20:39:19,283 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]3891
2023-04-17T20:39:19,284 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T20:39:19,284 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T20:39:19,284 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T20:39:19,284 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:19,284 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T20:39:19,284 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T20:39:19,285 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T20:39:19,285 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778359285
2023-04-17T20:39:19,285 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681778359285
2023-04-17T20:39:19,292 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T20:39:21,096 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T20:39:21,096 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T20:39:21,096 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:21,096 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T20:39:21,096 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T20:39:21,097 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:21,097 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T20:39:21,097 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:21,097 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T20:39:21,097 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T20:39:21,097 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:21,097 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T20:39:21,097 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T20:39:21,097 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T20:39:21,097 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:21,097 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T20:39:21,097 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T20:39:21,097 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:21,097 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T20:39:21,097 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T20:39:21,098 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:21,098 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2023-04-17T20:39:21,098 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T20:39:21,098 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2023-04-17T20:39:21,105 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T20:39:21,105 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:02:59,465 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:02:59,465 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:02:59,607 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:02:59,607 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:02:59,610 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:02:59,610 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:02:59,621 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:02:59,621 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:03:00,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:03:00,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:03:00,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:03:00,653 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:03:00,653 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:03:00,653 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:03:00,653 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:03:00,653 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:03:00,658 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:03:00,658 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:03:00,658 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:03:00,658 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:03:00,694 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:03:00,694 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:03:00,695 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:03:00,695 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:03:00,695 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:03:00,695 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:03:00,696 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:03:00,696 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:03:00,696 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:03:00,696 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:03:00,898 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:03:00,898 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:03:01,311 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,312 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.67441940307617|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,312 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.4924430847168|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,312 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,312 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:59.521484375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,313 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1219|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,313 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,313 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21972.4765625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,313 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3223.765625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,313 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:14.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779781
2023-04-17T21:03:01,452 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:03:01,454 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:03:01,454 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]21567
2023-04-17T21:03:01,454 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:03:01,455 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:03:01,454 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:03:01,455 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:03:01,457 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:03:01,457 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:03:01,460 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:03:01,462 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779781462
2023-04-17T21:03:01,462 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779781462
2023-04-17T21:03:01,473 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:03:02,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:03:02,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:03:02,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:03:02,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:03:02,900 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:03:02,900 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:03:02,900 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:03:02,900 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:03:02,900 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:03:02,900 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:03:02,900 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:03:02,900 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:03:02,900 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:03:02,900 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/e0426e9fe81f4b76a8c459e57079d3a3/tshandler.py", line 28, in initialize
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     process = subprocess.Popen(["./server/install.sh"])
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/subprocess.py", line 951, in __init__
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self._execute_child(args, executable, preexec_fn, close_fds,
2023-04-17T21:03:02,901 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/subprocess.py", line 1821, in _execute_child
2023-04-17T21:03:02,902 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     raise child_exception_type(errno_num, err_msg, err_filename)
2023-04-17T21:03:02,902 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - PermissionError: [Errno 13] Permission denied: './server/install.sh'
2023-04-17T21:03:02,900 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:03:02,900 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:03:02,908 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:03:02,908 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:03:02,908 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:03:02,908 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:03:02,908 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:03:02,908 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:03:02,908 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:03:02,908 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:03:02,909 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:03:02,909 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:03:02,915 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:03:02,915 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:03:02,915 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:03:02,915 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:03:03,909 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:03:03,909 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:03:04,627 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:03:04,630 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:03:04,630 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]21637
2023-04-17T21:03:04,630 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:03:04,630 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:03:04,630 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:03:04,630 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:03:04,630 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:03:04,630 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:03:04,631 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779784631
2023-04-17T21:03:04,631 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:03:04,631 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779784631
2023-04-17T21:03:04,641 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:03:06,071 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:03:06,072 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:03:06,072 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:03:06,072 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:03:06,072 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:03:06,072 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:03:06,072 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:03:06,072 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:03:06,073 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:03:06,073 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:03:06,073 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:03:06,073 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:03:06,073 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:03:06,073 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:03:06,073 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:03:06,073 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:03:06,073 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:03:06,073 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:03:06,073 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:03:06,073 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:03:06,073 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:03:06,073 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:03:06,073 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:03:06,073 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:03:06,073 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:03:06,073 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:03:06,074 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:03:06,074 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:03:06,074 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:03:06,074 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:03:06,079 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:03:06,079 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:03:07,074 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:03:07,074 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:03:07,796 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:03:07,799 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:03:07,799 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]21695
2023-04-17T21:03:07,799 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:03:07,799 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:03:07,799 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:03:07,799 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:03:07,799 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:03:07,799 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:03:07,800 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779787800
2023-04-17T21:03:07,800 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:03:07,800 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779787800
2023-04-17T21:03:07,808 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:03:09,238 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:03:09,239 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:03:09,239 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:03:09,239 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:03:09,239 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:03:09,239 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:03:09,239 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:03:09,240 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:03:09,239 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:03:09,240 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:03:09,240 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:03:09,240 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:03:09,240 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:03:09,240 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:03:09,240 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:03:09,240 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:03:09,240 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:03:09,240 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/e0426e9fe81f4b76a8c459e57079d3a3/tshandler.py", line 28, in initialize
2023-04-17T21:03:09,240 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:03:09,240 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:03:09,240 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     process = subprocess.Popen(["./server/install.sh"])
2023-04-17T21:03:09,240 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:03:09,241 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:03:09,241 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/subprocess.py", line 951, in __init__
2023-04-17T21:03:09,241 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:03:09,241 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:03:09,241 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:03:09,246 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:03:09,246 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:05:15,584 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:05:15,584 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:05:15,747 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:05:15,747 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:05:15,750 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:05:15,750 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:05:15,762 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:05:15,762 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:05:16,762 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:05:16,762 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:05:16,762 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:05:16,762 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:05:16,762 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:05:16,762 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:05:16,762 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:05:16,762 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:05:16,767 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:05:16,767 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:05:16,767 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:05:16,767 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:05:16,807 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:05:16,807 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:05:16,807 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:05:16,807 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:05:16,808 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:05:16,808 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:05:16,808 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:05:16,808 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:05:16,808 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:05:16,808 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:05:16,978 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:05:16,978 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:05:17,389 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,389 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.67400360107422|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,390 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.49285888671875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,390 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,390 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:62.890625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,390 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1288|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,390 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,390 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21917.4609375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,391 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3278.7734375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,391 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:14.4|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681779917
2023-04-17T21:05:17,565 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:05:17,567 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:05:17,567 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]7047
2023-04-17T21:05:17,567 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:05:17,568 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:05:17,568 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:05:17,568 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:05:17,570 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:05:17,570 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:05:17,574 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:05:17,575 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779917575
2023-04-17T21:05:17,575 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779917575
2023-04-17T21:05:17,587 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:05:19,013 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - /bin/sh: 1: ./server/install.sh: Permission denied
2023-04-17T21:05:19,394 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:05:19,395 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:05:19,395 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:05:19,395 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:05:19,395 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:05:19,395 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:05:19,395 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:05:19,396 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:05:19,396 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:05:19,396 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:05:19,396 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:05:19,397 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:05:19,397 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:05:19,397 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:05:19,397 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/08dd795797ad4336a84862db098a1b62/tshandler.py", line 33, in initialize
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from server.mask import mask_setup
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/08dd795797ad4336a84862db098a1b62/server/mask.py", line 8, in <module>
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from .get_mask.test import *
2023-04-17T21:05:19,398 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/08dd795797ad4336a84862db098a1b62/server/get_mask/test.py", line 30, in <module>
2023-04-17T21:05:19,399 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from .utils.pyvotkit.region import vot_overlap, vot_float2str
2023-04-17T21:05:19,399 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/08dd795797ad4336a84862db098a1b62/server/get_mask/utils/pyvotkit/__init__.py", line 9, in <module>
2023-04-17T21:05:19,399 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from . import region
2023-04-17T21:05:19,399 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ImportError: cannot import name 'region' from partially initialized module 'server.get_mask.utils.pyvotkit' (most likely due to a circular import) (/tmp/models/08dd795797ad4336a84862db098a1b62/server/get_mask/utils/pyvotkit/__init__.py)
2023-04-17T21:05:19,396 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:05:19,396 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:05:19,404 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:05:19,404 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:05:19,405 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:05:19,405 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:05:19,405 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:05:19,405 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:05:19,405 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:05:19,405 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:05:19,405 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:05:19,405 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:05:19,413 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:05:19,413 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:05:19,413 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:05:19,413 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:05:20,406 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:05:20,406 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:05:21,129 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:05:21,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:05:21,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]7113
2023-04-17T21:05:21,132 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:05:21,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:05:21,132 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:05:21,132 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:05:21,132 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:05:21,132 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:05:21,133 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:05:21,133 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779921133
2023-04-17T21:05:21,133 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779921133
2023-04-17T21:05:21,137 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:05:22,571 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - /bin/sh: 1: ./server/install.sh: Permission denied
2023-04-17T21:05:22,956 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:05:22,956 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:05:22,956 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:05:22,956 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:05:22,956 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:05:22,957 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:05:22,957 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:05:22,957 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:05:22,957 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:05:22,957 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:05:22,957 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:05:22,957 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:05:22,957 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:05:22,957 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:05:22,957 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:05:22,958 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:05:22,958 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:05:22,958 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:05:22,958 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:05:22,958 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:05:22,958 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:05:22,958 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:05:22,958 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:05:22,958 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:05:22,958 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:05:22,958 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:05:22,965 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:05:22,965 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:05:23,959 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:05:23,959 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:05:24,694 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:05:24,696 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:05:24,696 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]7140
2023-04-17T21:05:24,696 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:05:24,697 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:05:24,697 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:05:24,697 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:05:24,697 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:05:24,697 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:05:24,697 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:05:24,697 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779924697
2023-04-17T21:05:24,697 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681779924697
2023-04-17T21:05:24,706 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:07:25,459 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:07:25,459 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:07:25,627 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:07:25,627 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:07:25,630 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:07:25,630 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:07:25,642 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:07:25,642 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:07:26,669 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:07:26,669 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:07:26,669 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:07:26,669 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:07:26,669 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:07:26,669 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:07:26,669 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:07:26,669 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:07:26,674 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:26,674 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:07:26,674 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:26,674 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:07:26,710 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:07:26,710 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:07:26,710 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:07:26,710 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:07:26,711 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:07:26,711 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:07:26,711 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:07:26,711 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:07:26,712 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:07:26,712 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:07:26,879 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:07:26,879 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:07:27,291 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.67369079589844|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.49317169189453|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,292 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:66.50390625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,293 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1362|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,293 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21883.1875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3313.0546875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,293 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:14.6|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780047
2023-04-17T21:07:27,487 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:07:27,489 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:07:27,489 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]24309
2023-04-17T21:07:27,490 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:07:27,490 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:07:27,490 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:07:27,490 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:07:27,492 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:27,492 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:27,496 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:07:27,497 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780047497
2023-04-17T21:07:27,497 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780047497
2023-04-17T21:07:27,510 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:07:28,946 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - /bin/sh: 1: ./server/get_mask/make.sh: Permission denied
2023-04-17T21:07:29,339 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:07:29,339 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:07:29,339 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:07:29,340 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:07:29,340 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:07:29,340 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:07:29,340 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:07:29,340 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:07:29,340 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:07:29,341 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:07:29,341 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:07:29,341 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:07:29,341 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:07:29,341 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:07:29,342 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:07:29,342 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:07:29,342 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:07:29,342 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/ceae97443e02466583cecd9557934a29/tshandler.py", line 33, in initialize
2023-04-17T21:07:29,342 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from server.mask import mask_setup
2023-04-17T21:07:29,343 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/ceae97443e02466583cecd9557934a29/server/mask.py", line 8, in <module>
2023-04-17T21:07:29,343 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from .get_mask.test import *
2023-04-17T21:07:29,343 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/ceae97443e02466583cecd9557934a29/server/get_mask/test.py", line 30, in <module>
2023-04-17T21:07:29,343 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from .utils.pyvotkit.region import vot_overlap, vot_float2str
2023-04-17T21:07:29,343 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/ceae97443e02466583cecd9557934a29/server/get_mask/utils/pyvotkit/__init__.py", line 9, in <module>
2023-04-17T21:07:29,343 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from . import region
2023-04-17T21:07:29,344 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ImportError: cannot import name 'region' from partially initialized module 'server.get_mask.utils.pyvotkit' (most likely due to a circular import) (/tmp/models/ceae97443e02466583cecd9557934a29/server/get_mask/utils/pyvotkit/__init__.py)
2023-04-17T21:07:29,341 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:07:29,341 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:07:29,349 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:07:29,349 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:07:29,350 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:07:29,350 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:07:29,350 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:07:29,350 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:07:29,350 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:07:29,350 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:07:29,351 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:07:29,351 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:07:29,357 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:07:29,357 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:07:29,357 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:07:29,357 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:07:30,351 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:30,351 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:31,079 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:07:31,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:07:31,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]24365
2023-04-17T21:07:31,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:07:31,081 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:07:31,081 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:07:31,081 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:07:31,082 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:31,082 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:31,083 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780051083
2023-04-17T21:07:31,082 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:07:31,083 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780051083
2023-04-17T21:07:31,087 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:07:32,524 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - /bin/sh: 1: ./server/get_mask/make.sh: Permission denied
2023-04-17T21:07:32,913 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:07:32,914 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:07:32,914 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:07:32,914 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:07:32,914 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:07:32,914 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:07:32,914 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:07:32,914 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:07:32,914 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:07:32,914 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:07:32,914 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:07:32,914 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:07:32,915 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:07:32,915 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:07:32,915 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:07:32,915 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:07:32,915 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:07:32,915 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:07:32,915 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:07:32,915 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:07:32,915 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:07:32,915 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:07:32,915 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:07:32,915 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:07:32,915 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:07:32,915 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:07:32,922 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:07:32,922 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:07:33,916 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:33,916 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:34,627 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:07:34,629 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:07:34,629 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]24405
2023-04-17T21:07:34,629 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:07:34,629 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:07:34,629 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:07:34,630 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:34,630 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:34,630 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:07:34,630 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780054630
2023-04-17T21:07:34,630 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:07:34,630 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780054630
2023-04-17T21:07:34,639 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:07:36,053 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - /bin/sh: 1: ./server/get_mask/make.sh: Permission denied
2023-04-17T21:07:36,429 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:07:36,429 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:07:36,429 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:07:36,430 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:07:36,430 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:07:36,429 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:07:36,430 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:07:36,430 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:07:36,430 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:07:36,430 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:07:36,430 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:07:36,430 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:07:36,430 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:07:36,430 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:07:36,430 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:07:36,431 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:07:36,431 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:07:36,431 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:07:36,431 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:07:36,431 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:07:36,431 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:07:36,431 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:07:36,431 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:07:36,431 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:07:36,431 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:07:36,431 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:07:36,431 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:07:36,439 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:07:36,439 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:07:38,432 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:38,432 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:07:39,129 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:07:39,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:07:39,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]24448
2023-04-17T21:07:39,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:07:39,131 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:07:39,131 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:07:39,131 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:07:39,132 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:39,132 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:07:39,132 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:07:39,133 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780059133
2023-04-17T21:07:39,133 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780059133
2023-04-17T21:07:39,141 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:07:40,550 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - /bin/sh: 1: ./server/get_mask/make.sh: Permission denied
2023-04-17T21:12:37,590 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:12:37,590 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:12:37,747 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:12:37,747 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:12:37,750 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:12:37,750 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:12:37,762 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:12:37,762 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:12:38,774 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:12:38,774 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:12:38,774 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:12:38,774 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:12:38,775 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:12:38,775 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:12:38,775 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:12:38,775 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:12:38,779 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:12:38,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:12:38,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:12:38,779 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:12:38,818 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:12:38,818 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:12:38,819 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:12:38,819 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:12:38,819 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:12:38,819 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:12:38,820 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:12:38,820 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:12:38,820 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:12:38,820 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:12:38,978 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:12:38,978 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:12:39,394 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,394 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65325927734375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,395 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51360321044922|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,395 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,395 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:67.08984375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,395 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1374|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,395 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,395 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21875.734375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,396 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3320.5078125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,396 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:14.6|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780359
2023-04-17T21:12:39,622 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:12:39,624 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:12:39,624 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]9998
2023-04-17T21:12:39,624 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:12:39,625 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:12:39,625 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:12:39,625 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:12:39,627 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:12:39,627 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:12:39,631 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:12:39,632 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780359632
2023-04-17T21:12:39,632 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780359632
2023-04-17T21:12:39,644 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:12:41,459 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:12:41,460 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:12:41,460 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:12:41,460 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:12:41,460 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:12:41,460 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:12:41,460 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:12:41,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:12:41,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:12:41,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:12:41,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:12:41,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:12:41,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:12:41,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:12:41,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/abc95aaa6e0b4b84aee4651c120de02d/tshandler.py", line 42, in initialize
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/abc95aaa6e0b4b84aee4651c120de02d/server/mask.py", line 51, in mask_setup
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     cfg = load_config(args)
2023-04-17T21:12:41,463 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/abc95aaa6e0b4b84aee4651c120de02d/server/get_mask/utils/config_helper.py", line 11, in load_config
2023-04-17T21:12:41,464 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     assert exists(args.config), '"{}" not exists'.format(args.config)
2023-04-17T21:12:41,464 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - AssertionError: "get_mask/experiments/siammask/config_davis.json" not exists
2023-04-17T21:12:41,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:12:41,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:12:41,468 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:12:41,468 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:12:41,468 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:12:41,468 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:12:41,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:12:41,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:12:41,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:12:41,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:12:41,470 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:12:41,470 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:12:41,477 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:12:41,477 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:12:41,477 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:12:41,477 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:12:42,470 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:12:42,470 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:12:43,190 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:12:43,193 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:12:43,193 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]10062
2023-04-17T21:12:43,193 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:12:43,193 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:12:43,193 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:12:43,193 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:12:43,193 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:12:43,193 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:12:43,194 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:12:43,194 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780363194
2023-04-17T21:12:43,194 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780363194
2023-04-17T21:12:43,199 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:12:45,023 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:12:45,023 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:12:45,023 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:12:45,024 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:12:45,023 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:12:45,024 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:12:45,024 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:12:45,024 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:12:45,024 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:12:45,024 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:12:45,024 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:12:45,024 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:12:45,024 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:12:45,024 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:12:45,025 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:12:45,025 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:12:45,025 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:12:45,025 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:12:45,025 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:12:45,025 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:12:45,025 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:12:45,025 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:12:45,025 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:12:45,025 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:12:45,025 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:12:45,025 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:12:45,032 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:12:45,032 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:12:46,026 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:12:46,026 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:12:46,743 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:12:46,745 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:12:46,746 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]10099
2023-04-17T21:12:46,746 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:12:46,746 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:12:46,746 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:12:46,746 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:12:46,746 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:12:46,746 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:12:46,747 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:12:46,747 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780366747
2023-04-17T21:12:46,747 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780366747
2023-04-17T21:12:46,756 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:12:50,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:12:50,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:12:50,985 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:12:50,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:12:50,985 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:12:50,985 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:12:50,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:12:50,985 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:12:50,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:12:50,985 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:12:50,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:12:50,985 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:12:50,985 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:12:50,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:12:50,985 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:12:50,986 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:12:50,986 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:12:50,986 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:12:50,986 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:12:50,986 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:12:50,986 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:12:50,986 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:12:50,986 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:12:50,986 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:12:50,986 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:12:50,986 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:12:50,994 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:12:50,994 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:18:47,732 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:18:47,732 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:18:47,917 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:18:47,917 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:18:47,920 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:18:47,920 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:18:47,931 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:18:47,931 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:18:48,958 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:18:48,958 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:18:48,959 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:18:48,959 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:18:48,959 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:18:48,959 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:18:48,959 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:18:48,959 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:18:48,963 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:18:48,963 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:18:48,964 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:18:48,964 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:18:49,006 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:18:49,006 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:18:49,007 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:18:49,007 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:18:49,007 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:18:49,007 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:18:49,008 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:18:49,008 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:18:49,008 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:18:49,008 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:18:49,198 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:18:49,198 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:18:49,578 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,579 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65230560302734|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,579 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51455688476562|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,579 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,579 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:65.52734375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,579 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1342|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,580 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,580 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21706.8984375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,580 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3489.34375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,580 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780729
2023-04-17T21:18:49,738 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:18:49,740 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:18:49,740 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]27752
2023-04-17T21:18:49,740 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:18:49,740 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:18:49,740 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:18:49,740 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:18:49,743 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:18:49,743 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:18:49,746 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:18:49,748 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780729748
2023-04-17T21:18:49,748 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780729748
2023-04-17T21:18:49,759 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:18:51,576 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:18:51,576 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:18:51,576 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:18:51,577 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:18:51,577 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:18:51,577 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:18:51,577 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:18:51,577 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:18:51,578 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:18:51,577 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:18:51,578 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:18:51,578 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:18:51,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:18:51,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:18:51,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:18:51,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:18:51,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:18:51,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/1ab08f1f427d4d2884214912c1b81f74/tshandler.py", line 42, in initialize
2023-04-17T21:18:51,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:18:51,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/1ab08f1f427d4d2884214912c1b81f74/server/mask.py", line 68, in mask_setup
2023-04-17T21:18:51,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     cfg = local_load_config(args)
2023-04-17T21:18:51,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/1ab08f1f427d4d2884214912c1b81f74/server/mask.py", line 15, in local_load_config
2023-04-17T21:18:51,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     assert os.path.exists(args.config), '"{}" not exists'.format(args.config)
2023-04-17T21:18:51,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - AssertionError: "get_mask/experiments/siammask/config_davis.json" not exists
2023-04-17T21:18:51,578 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:18:51,578 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:18:51,585 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:18:51,585 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:18:51,585 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:18:51,585 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:18:51,586 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:18:51,586 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:18:51,586 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:18:51,586 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:18:51,586 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:18:51,586 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:18:51,593 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:18:51,593 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:18:51,594 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:18:51,594 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:18:52,587 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:18:52,587 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:18:53,307 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:18:53,309 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:18:53,310 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]27806
2023-04-17T21:18:53,310 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:18:53,310 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:18:53,310 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:18:53,310 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:18:53,310 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:18:53,310 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:18:53,311 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:18:53,311 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780733311
2023-04-17T21:18:53,311 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780733311
2023-04-17T21:18:53,316 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:18:57,538 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:18:57,538 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:18:57,538 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:18:57,539 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:18:57,538 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:18:57,539 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:18:57,539 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:18:57,539 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:18:57,539 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:18:57,539 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:18:57,539 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:18:57,539 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:18:57,539 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:18:57,540 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:18:57,540 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:18:57,540 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:18:57,540 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:18:57,540 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:18:57,540 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:18:57,540 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:18:57,540 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:18:57,540 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:18:57,540 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:18:57,540 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:18:57,540 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:18:57,540 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:18:57,548 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:18:57,548 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:18:58,541 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:18:58,541 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:18:59,262 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:18:59,264 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:18:59,264 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]27852
2023-04-17T21:18:59,264 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:18:59,264 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:18:59,264 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:18:59,265 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:18:59,265 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:18:59,265 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:18:59,265 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:18:59,266 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780739266
2023-04-17T21:18:59,266 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780739266
2023-04-17T21:18:59,274 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:20:38,603 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:20:38,603 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:20:38,727 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:20:38,727 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:20:38,730 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:20:38,730 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:20:38,741 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:20:38,741 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:20:39,758 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:20:39,758 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:20:39,759 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:20:39,759 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:20:39,759 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:20:39,759 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:20:39,759 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:20:39,759 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:20:39,763 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:39,763 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:39,764 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:20:39,764 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:20:39,797 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:20:39,797 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:20:39,798 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:20:39,798 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:20:39,805 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:20:39,805 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:20:39,806 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:20:39,806 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:20:39,806 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:20:39,806 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:20:39,987 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:20:39,987 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:20:40,380 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:75.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,380 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65226364135742|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,380 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51459884643555|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,381 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,381 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:64.0625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,381 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1312|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,381 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,381 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21722.08984375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,382 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3474.140625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,382 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681780840
2023-04-17T21:20:40,534 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:20:40,536 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:20:40,536 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]12868
2023-04-17T21:20:40,536 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:20:40,537 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:20:40,537 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:20:40,537 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:20:40,539 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:20:40,539 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:20:40,543 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:20:40,544 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780840544
2023-04-17T21:20:40,544 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780840544
2023-04-17T21:20:40,557 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:20:42,368 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:20:42,369 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:20:42,369 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:20:42,369 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:20:42,369 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:20:42,369 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:20:42,370 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:20:42,370 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:20:42,370 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:20:42,370 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:20:42,370 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:20:42,371 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:20:42,371 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/5a6d15ecccf3497f9c35e19a264cea9e/tshandler.py", line 42, in initialize
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:20:42,372 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/5a6d15ecccf3497f9c35e19a264cea9e/server/mask.py", line 68, in mask_setup
2023-04-17T21:20:42,373 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     cfg = local_load_config(args)
2023-04-17T21:20:42,373 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/5a6d15ecccf3497f9c35e19a264cea9e/server/mask.py", line 15, in local_load_config
2023-04-17T21:20:42,373 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     assert os.path.exists(args.config), '"{}" not exists'.format(args.config)
2023-04-17T21:20:42,373 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - AssertionError: "./get_mask/experiments/siammask/config_davis.json" not exists
2023-04-17T21:20:42,370 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:20:42,370 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:20:42,378 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:20:42,378 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:20:42,378 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:20:42,378 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:20:42,378 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:20:42,378 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:20:42,378 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:20:42,378 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:20:42,379 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:20:42,379 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:20:42,386 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:20:42,386 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:20:42,386 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:20:42,386 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:20:43,379 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:43,379 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:44,087 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:20:44,089 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:20:44,089 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]12934
2023-04-17T21:20:44,089 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:20:44,089 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:20:44,089 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:20:44,089 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:20:44,089 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:20:44,089 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:20:44,090 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:20:44,090 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780844090
2023-04-17T21:20:44,090 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780844090
2023-04-17T21:20:44,095 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:20:45,922 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:20:45,923 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:20:45,923 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:20:45,923 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:20:45,923 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:20:45,923 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:20:45,923 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:20:45,923 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:20:45,923 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:20:45,924 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:20:45,924 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:20:45,924 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:20:45,924 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:20:45,924 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:20:45,924 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:20:45,924 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:20:45,924 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:20:45,924 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:20:45,924 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:20:45,925 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:20:45,924 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:20:45,925 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:20:45,925 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:20:45,925 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:20:45,925 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:20:45,925 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:20:45,925 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:20:45,933 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:20:45,933 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:20:46,925 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:46,925 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:47,652 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:20:47,654 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:20:47,654 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]12959
2023-04-17T21:20:47,654 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:20:47,654 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:20:47,654 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:20:47,654 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:20:47,655 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:20:47,655 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:20:47,655 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780847655
2023-04-17T21:20:47,655 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:20:47,655 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681780847655
2023-04-17T21:20:47,664 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:20:49,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:20:49,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:20:49,461 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:20:49,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:20:49,461 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:20:49,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:20:49,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:20:49,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:20:49,461 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:20:49,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:20:49,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:20:49,461 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:20:49,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:20:49,462 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:20:49,462 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:20:49,462 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:20:49,462 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:20:49,462 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:20:49,462 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:20:49,462 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:20:49,462 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:20:49,462 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:20:49,462 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:20:49,462 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:20:49,463 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:20:49,463 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:20:49,470 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:20:49,470 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:20:51,463 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:20:51,463 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:03,035 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:24:03,035 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:24:03,146 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:24:03,146 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:24:03,150 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:24:03,150 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:24:03,161 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:24:03,161 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:24:04,169 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:24:04,169 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:24:04,170 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:24:04,170 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:24:04,170 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:24:04,170 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:24:04,170 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:24:04,170 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:24:04,174 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:04,174 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:04,175 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:24:04,175 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:24:04,212 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:24:04,212 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:24:04,212 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:24:04,212 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:24:04,213 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:24:04,213 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:24:04,213 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:24:04,213 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:24:04,214 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:24:04,214 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:24:04,397 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:24:04,397 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:24:04,806 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,806 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65216827392578|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,806 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51469421386719|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,806 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,807 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:68.310546875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,807 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1399|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,807 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,807 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21587.359375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,808 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3608.8828125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,808 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.7|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781044
2023-04-17T21:24:04,947 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:24:04,949 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:24:04,949 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]30460
2023-04-17T21:24:04,949 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:24:04,949 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:24:04,949 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:24:04,949 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:24:04,952 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:24:04,952 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:24:04,956 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:24:04,957 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781044957
2023-04-17T21:24:04,957 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781044957
2023-04-17T21:24:04,968 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:24:06,917 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:24:06,918 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:24:06,918 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:24:06,919 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:24:06,919 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:24:06,919 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:24:06,919 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:24:06,919 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:24:06,919 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:24:06,920 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:24:06,920 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:24:06,920 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:24:06,920 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:24:06,920 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:24:06,920 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:24:06,921 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:24:06,921 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:24:06,921 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/1569e463d9dd4ecfa61c4a06805f3857/tshandler.py", line 42, in initialize
2023-04-17T21:24:06,921 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:24:06,921 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/1569e463d9dd4ecfa61c4a06805f3857/server/mask.py", line 90, in mask_setup
2023-04-17T21:24:06,922 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     assert isfile(args.resume), '{} is not a valid file'.format(args.resume)
2023-04-17T21:24:06,922 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - AssertionError: cp/SiamMask_DAVIS.pth is not a valid file
2023-04-17T21:24:06,920 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:24:06,920 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:24:06,928 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:24:06,928 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:24:06,928 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:24:06,928 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:24:06,928 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:24:06,928 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:24:06,928 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:24:06,928 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:24:06,929 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:24:06,929 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:24:06,936 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:24:06,936 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:24:06,936 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:24:06,936 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:24:07,929 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:07,929 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:08,666 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:24:08,668 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:24:08,669 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]30527
2023-04-17T21:24:08,669 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:24:08,669 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:24:08,669 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:24:08,669 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:24:08,669 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:24:08,669 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:24:08,670 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:24:08,670 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781048670
2023-04-17T21:24:08,670 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781048670
2023-04-17T21:24:08,675 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:24:10,614 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:24:10,614 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:24:10,614 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:24:10,615 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:24:10,615 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:24:10,615 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:24:10,615 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:24:10,615 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:24:10,615 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:24:10,615 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:24:10,615 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:24:10,616 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:24:10,616 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:24:10,616 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:24:10,616 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:24:10,616 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:24:10,616 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:24:10,616 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:24:10,616 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:24:10,616 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:24:10,616 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:24:10,616 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:24:10,617 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:24:10,617 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:24:10,617 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:24:10,617 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:24:10,617 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:24:10,617 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:24:10,617 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:24:10,626 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:24:10,626 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:24:11,617 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:11,617 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:24:12,346 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:24:12,348 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:24:12,348 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]30552
2023-04-17T21:24:12,349 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:24:12,349 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:24:12,349 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:24:12,349 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:24:12,349 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:24:12,349 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:24:12,350 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:24:12,350 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781052350
2023-04-17T21:24:12,350 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781052350
2023-04-17T21:24:12,359 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:24:14,327 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:24:14,327 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:24:14,328 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:24:14,328 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:24:14,328 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:24:14,328 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:24:14,328 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:24:14,328 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:24:14,328 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:24:14,328 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:24:14,328 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:24:14,329 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:24:14,329 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:24:14,329 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:24:14,329 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:24:14,329 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:24:14,329 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:24:14,329 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:24:14,329 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:24:14,329 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:24:14,329 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:24:14,329 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:24:14,330 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:24:14,330 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:24:14,330 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:24:14,330 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:24:14,330 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:24:14,330 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/1569e463d9dd4ecfa61c4a06805f3857/tshandler.py", line 42, in initialize
2023-04-17T21:24:14,330 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:24:14,330 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:24:14,330 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:24:14,330 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:24:14,338 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:24:14,338 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:27:46,182 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:27:46,182 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:27:46,306 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:27:46,306 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:27:46,310 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:27:46,310 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:27:46,321 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:27:46,321 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:27:47,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:27:47,351 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:27:47,352 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:27:47,352 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:27:47,352 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:27:47,352 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:27:47,352 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:27:47,352 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:27:47,356 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:27:47,356 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:27:47,357 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:27:47,357 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:27:47,391 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:27:47,391 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:27:47,392 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:27:47,392 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:27:47,400 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:27:47,400 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:27:47,400 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:27:47,400 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:27:47,401 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:27:47,401 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:27:47,567 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:27:47,567 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:27:47,964 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65191650390625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51494598388672|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,965 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,966 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:59.47265625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,966 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1218|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,966 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,966 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21682.25390625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,966 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3513.98828125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:47,966 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781267
2023-04-17T21:27:48,166 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:27:48,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:27:48,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]15984
2023-04-17T21:27:48,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:27:48,169 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:27:48,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:27:48,169 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:27:48,171 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:27:48,171 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:27:48,175 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:27:48,176 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781268176
2023-04-17T21:27:48,176 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781268176
2023-04-17T21:27:48,188 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:27:49,981 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:27:49,981 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:27:49,982 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:27:49,982 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:27:49,982 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:27:49,982 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:27:49,982 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:27:49,983 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:27:49,983 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/fc46d9df694744e0ad38cd7ee64729e0/tshandler.py", line 33, in initialize
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from server.mask import mask_setup
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/fc46d9df694744e0ad38cd7ee64729e0/server/mask.py", line 8, in <module>
2023-04-17T21:27:49,984 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from get_mask.test import *
2023-04-17T21:27:49,985 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ModuleNotFoundError: No module named 'get_mask'
2023-04-17T21:27:50,031 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:27:50,031 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:27:50,032 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:27:50,032 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:27:50,032 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:27:50,032 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:27:50,039 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:27:50,039 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:27:50,040 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:27:50,040 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:27:50,040 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:27:50,040 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:27:50,040 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:27:50,040 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:27:50,040 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:27:50,040 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:27:50,048 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:27:50,048 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:27:50,048 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:27:50,048 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:27:51,041 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:27:51,041 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:27:51,755 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:27:51,757 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:27:51,757 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]16053
2023-04-17T21:27:51,757 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:27:51,757 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:27:51,757 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:27:51,757 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:27:51,757 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:27:51,757 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:27:51,758 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781271758
2023-04-17T21:27:51,758 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:27:51,758 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781271758
2023-04-17T21:27:51,763 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:27:53,578 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:27:53,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:27:53,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:27:53,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:27:53,579 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:27:53,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:27:53,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:27:53,580 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/fc46d9df694744e0ad38cd7ee64729e0/tshandler.py", line 33, in initialize
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from server.mask import mask_setup
2023-04-17T21:27:53,581 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/fc46d9df694744e0ad38cd7ee64729e0/server/mask.py", line 8, in <module>
2023-04-17T21:27:53,582 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from get_mask.test import *
2023-04-17T21:27:53,582 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ModuleNotFoundError: No module named 'get_mask'
2023-04-17T21:27:53,626 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:27:53,626 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:27:53,627 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:27:53,627 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:27:53,627 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:27:53,627 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:27:53,628 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:27:53,628 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:27:53,628 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:27:53,628 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:27:53,628 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:27:53,628 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:27:53,628 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:27:53,628 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:27:53,628 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:27:53,628 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:27:53,635 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:27:53,635 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:27:53,635 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:27:53,635 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:27:54,629 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:27:54,629 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:27:55,354 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:27:55,356 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:27:55,357 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]16087
2023-04-17T21:27:55,357 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:27:55,357 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:27:55,357 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:27:55,357 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:27:55,357 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:27:55,357 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:27:55,358 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:27:55,358 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781275358
2023-04-17T21:27:55,358 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781275358
2023-04-17T21:27:55,366 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:27:57,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:27:57,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:27:57,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:27:57,168 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:27:57,169 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:27:57,169 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:27:57,169 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:27:57,169 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/fc46d9df694744e0ad38cd7ee64729e0/tshandler.py", line 33, in initialize
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from server.mask import mask_setup
2023-04-17T21:27:57,170 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/fc46d9df694744e0ad38cd7ee64729e0/server/mask.py", line 8, in <module>
2023-04-17T21:27:57,171 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     from get_mask.test import *
2023-04-17T21:27:57,171 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ModuleNotFoundError: No module named 'get_mask'
2023-04-17T21:27:57,215 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:27:57,215 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:27:57,216 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:27:57,216 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:27:57,216 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:27:57,216 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:27:57,216 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:27:57,216 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:27:57,216 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:27:57,216 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:27:57,217 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:27:57,217 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:27:57,217 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:27:57,217 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:27:57,217 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:27:57,217 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:27:57,224 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:27:57,224 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:27:57,224 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:27:57,224 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:42,403 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:28:42,403 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:28:42,546 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:28:42,546 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:28:42,550 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:28:42,550 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:28:42,561 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:28:42,561 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:28:43,580 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:28:43,580 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:28:43,580 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:28:43,580 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:28:43,580 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:28:43,580 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:28:43,580 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:28:43,580 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:28:43,585 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:43,585 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:28:43,585 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:28:43,585 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:43,617 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:28:43,617 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:28:43,617 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:28:43,617 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:28:43,625 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:28:43,625 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:28:43,625 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:28:43,625 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:28:43,626 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:28:43,626 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:28:43,777 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:28:43,777 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:28:44,181 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,181 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.6518669128418|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,181 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51499557495117|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,182 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,182 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:59.423828125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,182 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1217|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,182 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,182 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21673.0078125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,182 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3523.7265625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,183 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.4|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781324
2023-04-17T21:28:44,385 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:28:44,387 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:28:44,387 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]1072
2023-04-17T21:28:44,387 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:28:44,388 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:28:44,387 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:28:44,388 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:28:44,390 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:44,390 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:44,394 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:28:44,395 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781324395
2023-04-17T21:28:44,395 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781324395
2023-04-17T21:28:44,406 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:28:46,345 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:28:46,345 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:28:46,345 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:28:46,345-rk0-load_helper.py# 31] load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:46,346 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:46,375 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:28:46,375 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:28:46,375 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:28:46,376 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:28:46,376 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:28:46,376 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:28:46,377 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:28:46,377 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:28:46,377 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:28:46,377 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:46,377 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:28:46,377 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:46,377 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:28:46,377 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:46,377 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:28:46,377 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:46,378 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/tshandler.py", line 42, in initialize
2023-04-17T21:28:46,378 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:28:46,378 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/mask.py", line 92, in mask_setup
2023-04-17T21:28:46,378 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     siammask = load_pretrain(siammask, args.resume)
2023-04-17T21:28:46,378 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/get_mask/utils/load_helper.py", line 33, in load_pretrain
2023-04-17T21:28:46,378 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
2023-04-17T21:28:46,379 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
2023-04-17T21:28:46,379 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     with _open_file_like(f, 'rb') as opened_file:
2023-04-17T21:28:46,380 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 271, in _open_file_like
2023-04-17T21:28:46,380 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     return _open_file(name_or_buffer, mode)
2023-04-17T21:28:46,380 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 252, in __init__
2023-04-17T21:28:46,381 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     super().__init__(open(name, mode))
2023-04-17T21:28:46,381 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: 'cp/SiamMask_DAVIS.pth'
2023-04-17T21:28:46,378 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:46,378 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:46,386 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:46,386 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:46,386 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:46,386 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:46,386 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:46,386 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:46,386 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:46,386 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:46,387 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:28:46,387 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:28:46,394 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:46,394 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:46,394 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:46,394 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:47,387 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:47,387 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:48,085 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:28:48,087 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:28:48,087 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]1128
2023-04-17T21:28:48,087 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:28:48,087 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:28:48,087 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:28:48,087 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:28:48,087 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:48,087 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:48,088 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781328088
2023-04-17T21:28:48,088 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:28:48,088 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781328088
2023-04-17T21:28:48,093 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:28:50,026 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:28:50,026 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:28:50,027 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:50,026 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:28:50,026-rk0-load_helper.py# 31] load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:50,056 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:28:50,057 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:28:50,058 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:28:50,058 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/tshandler.py", line 42, in initialize
2023-04-17T21:28:50,058 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:50,058 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:28:50,058 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/mask.py", line 92, in mask_setup
2023-04-17T21:28:50,058 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     siammask = load_pretrain(siammask, args.resume)
2023-04-17T21:28:50,058 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:50,058 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:50,058 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:50,058 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/get_mask/utils/load_helper.py", line 33, in load_pretrain
2023-04-17T21:28:50,058 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:50,059 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
2023-04-17T21:28:50,059 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:50,059 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:50,059 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:50,059 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:50,059 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:28:50,059 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:28:50,059 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
2023-04-17T21:28:50,059 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:50,059 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:50,067 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:50,067 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:51,060 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:51,060 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:51,764 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:28:51,766 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:28:51,767 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]1165
2023-04-17T21:28:51,767 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:28:51,767 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:28:51,767 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:28:51,767 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:51,767 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:28:51,767 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:51,768 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:28:51,768 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781331768
2023-04-17T21:28:51,768 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781331768
2023-04-17T21:28:51,777 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:28:53,719 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:28:53,719 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:28:53,719 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:28:53,718-rk0-load_helper.py# 31] load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:53,719 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:53,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:28:53,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:28:53,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:28:53,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:28:53,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:28:53,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:28:53,752 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:28:53,752 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:28:53,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/tshandler.py", line 42, in initialize
2023-04-17T21:28:53,752 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:53,752 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/mask.py", line 92, in mask_setup
2023-04-17T21:28:53,753 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:53,753 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     siammask = load_pretrain(siammask, args.resume)
2023-04-17T21:28:53,753 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:53,753 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/get_mask/utils/load_helper.py", line 33, in load_pretrain
2023-04-17T21:28:53,753 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:53,753 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
2023-04-17T21:28:53,753 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:53,753 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:53,753 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:53,753 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:28:53,753 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2023-04-17T21:28:53,754 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
2023-04-17T21:28:53,754 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:53,754 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:53,761 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:53,761 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:55,754 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:55,754 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:28:56,498 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:28:56,500 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:28:56,500 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]1205
2023-04-17T21:28:56,500 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:28:56,500 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:28:56,500 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:28:56,500 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:28:56,500 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:56,500 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:28:56,501 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781336501
2023-04-17T21:28:56,501 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781336501
2023-04-17T21:28:56,501 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:28:56,512 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:28:58,434 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:28:58,434 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:28:58,434 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:58,434 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:28:58,434-rk0-load_helper.py# 31] load pretrained model from cp/SiamMask_DAVIS.pth
2023-04-17T21:28:58,467 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:28:58,467 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:28:58,467 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:28:58,467 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:28:58,467 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:28:58,467 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:28:58,468 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:28:58,468 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/tshandler.py", line 42, in initialize
2023-04-17T21:28:58,468 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:58,468 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:28:58,468 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:28:58,469 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/mask.py", line 92, in mask_setup
2023-04-17T21:28:58,469 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:58,469 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:28:58,469 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     siammask = load_pretrain(siammask, args.resume)
2023-04-17T21:28:58,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:58,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:28:58,469 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/eeff7869393b49bd87bac53024b157c1/server/get_mask/utils/load_helper.py", line 33, in load_pretrain
2023-04-17T21:28:58,469 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:58,469 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:28:58,469 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
2023-04-17T21:28:58,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:58,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:28:58,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:58,469 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:28:58,469 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2023-04-17T21:28:58,469 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2023-04-17T21:28:58,470 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
2023-04-17T21:28:58,470 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:58,470 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:28:58,477 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:28:58,477 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:29:01,470 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:29:01,470 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:29:02,174 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:29:02,176 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:29:02,176 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]1245
2023-04-17T21:29:02,176 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:29:02,176 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:29:02,176 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:29:02,176 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:29:02,176 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:29:02,176 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:29:02,177 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781342177
2023-04-17T21:29:02,177 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:29:02,177 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781342177
2023-04-17T21:29:02,186 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:31:33,108 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:31:33,108 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:31:33,246 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:31:33,246 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:31:33,250 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:31:33,250 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:31:33,261 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:31:33,261 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:31:34,294 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:31:34,294 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:31:34,294 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:31:34,294 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:31:34,295 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:31:34,295 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:31:34,295 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:31:34,295 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:31:34,299 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:31:34,299 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:31:34,299 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:31:34,299 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:31:34,331 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:31:34,331 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:31:34,331 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:31:34,331 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:31:34,339 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:31:34,339 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:31:34,339 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:31:34,339 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:31:34,340 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:31:34,340 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:31:34,517 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:31:34,517 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:31:34,930 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,930 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65179061889648|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,931 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51507186889648|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,931 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,931 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:61.62109375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,931 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1262|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,931 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,932 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21646.99609375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,932 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3549.24609375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:34,932 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.5|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781494
2023-04-17T21:31:35,076 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:31:35,077 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:31:35,078 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]18836
2023-04-17T21:31:35,078 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:31:35,078 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:31:35,078 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:31:35,078 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:31:35,081 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:31:35,081 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:31:35,084 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:31:35,086 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781495086
2023-04-17T21:31:35,086 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781495086
2023-04-17T21:31:35,097 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:31:37,035 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:31:37,035 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:31:37,035-rk0-load_helper.py# 31] load pretrained model from ./cp/SiamMask_DAVIS.pth
2023-04-17T21:31:37,035 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:31:37,036 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from ./cp/SiamMask_DAVIS.pth
2023-04-17T21:31:37,065 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:31:37,065 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:31:37,065 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:31:37,066 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:31:37,066 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:31:37,066 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:31:37,066 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:31:37,066 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:31:37,067 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:31:37,067 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:31:37,067 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:31:37,067 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/dd613f95083142aaaf3532946a4824fa/tshandler.py", line 42, in initialize
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:31:37,067 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/dd613f95083142aaaf3532946a4824fa/server/mask.py", line 92, in mask_setup
2023-04-17T21:31:37,068 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     siammask = load_pretrain(siammask, args.resume)
2023-04-17T21:31:37,068 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/dd613f95083142aaaf3532946a4824fa/server/get_mask/utils/load_helper.py", line 33, in load_pretrain
2023-04-17T21:31:37,068 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
2023-04-17T21:31:37,069 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
2023-04-17T21:31:37,069 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     with _open_file_like(f, 'rb') as opened_file:
2023-04-17T21:31:37,069 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 271, in _open_file_like
2023-04-17T21:31:37,069 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     return _open_file(name_or_buffer, mode)
2023-04-17T21:31:37,070 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 252, in __init__
2023-04-17T21:31:37,070 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     super().__init__(open(name, mode))
2023-04-17T21:31:37,070 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - FileNotFoundError: [Errno 2] No such file or directory: './cp/SiamMask_DAVIS.pth'
2023-04-17T21:31:37,067 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:31:37,067 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:31:37,075 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:31:37,075 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:31:37,075 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:31:37,075 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:31:37,075 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:31:37,075 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:31:37,075 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:31:37,075 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:31:37,076 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:31:37,076 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:31:37,083 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:31:37,083 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:31:37,083 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:31:37,083 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:31:38,076 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:31:38,076 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:31:38,792 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:31:38,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:31:38,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]18901
2023-04-17T21:31:38,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:31:38,794 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:31:38,794 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:31:38,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:31:38,795 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:31:38,795 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:31:38,796 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781498796
2023-04-17T21:31:38,796 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781498796
2023-04-17T21:31:38,796 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:31:38,800 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:31:40,738 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:31:40,738 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:31:40,738 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:31:40,737-rk0-load_helper.py# 31] load pretrained model from ./cp/SiamMask_DAVIS.pth
2023-04-17T21:31:40,738 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from ./cp/SiamMask_DAVIS.pth
2023-04-17T21:31:40,771 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:31:40,771 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:31:40,771 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:31:40,771 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:31:40,771 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:31:40,772 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:31:40,772 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:31:40,772 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:31:40,773 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:31:40,773 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:31:40,773 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/dd613f95083142aaaf3532946a4824fa/tshandler.py", line 42, in initialize
2023-04-17T21:31:40,773 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.siammask = mask_setup(args)
2023-04-17T21:31:40,773 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:31:40,773 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:31:40,773 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/dd613f95083142aaaf3532946a4824fa/server/mask.py", line 92, in mask_setup
2023-04-17T21:31:40,773 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:31:40,773 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     siammask = load_pretrain(siammask, args.resume)
2023-04-17T21:31:40,773 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:31:40,773 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:31:40,773 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/dd613f95083142aaaf3532946a4824fa/server/get_mask/utils/load_helper.py", line 33, in load_pretrain
2023-04-17T21:31:40,773 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:31:40,773 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     pretrained_dict = torch.load(pretrained_path, map_location=lambda storage, loc: storage.cuda(device))
2023-04-17T21:31:40,774 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:31:40,774 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:31:40,774 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:31:40,774 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:31:40,774 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:31:40,774 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:31:40,774 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
2023-04-17T21:31:40,774 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:31:40,774 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:31:40,782 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:31:40,782 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:31:41,775 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:31:41,775 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:31:42,532 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:31:42,534 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:31:42,535 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]18926
2023-04-17T21:31:42,535 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:31:42,535 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:31:42,535 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:31:42,535 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:31:42,535 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:31:42,535 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:31:42,536 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781502536
2023-04-17T21:31:42,536 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:31:42,536 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781502536
2023-04-17T21:31:42,545 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:32:33,629 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:32:33,629 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:32:33,776 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:32:33,776 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:32:33,780 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:32:33,780 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:32:33,791 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:32:33,791 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:32:34,809 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:32:34,809 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:32:34,810 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:32:34,810 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:32:34,810 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:32:34,810 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:32:34,810 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:32:34,810 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:32:34,815 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:32:34,815 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:32:34,815 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:32:34,815 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:32:34,847 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:32:34,847 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:32:34,847 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:32:34,847 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:32:34,856 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:32:34,856 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:32:34,856 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:32:34,856 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:32:34,857 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:32:34,857 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:32:35,017 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:32:35,017 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:32:35,451 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,451 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65175247192383|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,452 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51511001586914|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,452 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,452 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:63.720703125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,452 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1305|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,452 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,453 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21694.890625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,453 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3501.3515625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,453 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781555
2023-04-17T21:32:35,666 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:32:35,667 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:32:35,668 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]3922
2023-04-17T21:32:35,668 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:32:35,668 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:32:35,668 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:32:35,668 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:32:35,671 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:32:35,671 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:32:35,674 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:32:35,675 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781555675
2023-04-17T21:32:35,675 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781555675
2023-04-17T21:32:35,687 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:32:37,627 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:32:37,628 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:32:37,627 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:32:37,627-rk0-load_helper.py# 31] load pretrained model from ./server/cp/SiamMask_DAVIS.pth
2023-04-17T21:32:37,628 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from ./server/cp/SiamMask_DAVIS.pth
2023-04-17T21:32:38,708 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:32:38,708-rk0-load_helper.py# 25] remove prefix 'module.'
2023-04-17T21:32:38,708 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - remove prefix 'module.'
2023-04-17T21:32:38,709 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:32:38,709-rk0-load_helper.py# 18] used keys:356
2023-04-17T21:32:38,709 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - used keys:356
2023-04-17T21:32:38,747 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:32:38,747 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:32:38,748 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:32:38,748 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:32:38,748 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:32:38,748 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:32:38,748 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:32:38,748 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:32:38,749 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:32:38,749 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:32:38,749 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:32:38,749 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:32:38,749 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/29c91633e1c64db295e334a5f8508734/tshandler.py", line 51, in initialize
2023-04-17T21:32:38,749 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:32:38,749 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     model, size = setup(args)
2023-04-17T21:32:38,749 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:32:38,750 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/29c91633e1c64db295e334a5f8508734/server/E2FGVI/test.py", line 133, in setup
2023-04-17T21:32:38,750 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     net = importlib.import_module('model.' + args.model)
2023-04-17T21:32:38,750 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:32:38,750 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:32:38,750 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-04-17T21:32:38,750 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-04-17T21:32:38,750 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-04-17T21:32:38,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-04-17T21:32:38,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2023-04-17T21:32:38,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2023-04-17T21:32:38,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2023-04-17T21:32:38,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2023-04-17T21:32:38,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2023-04-17T21:32:38,752 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - ModuleNotFoundError: No module named 'model'
2023-04-17T21:32:38,750 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:32:38,750 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:32:38,757 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:32:38,757 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:32:38,758 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:32:38,758 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:32:38,758 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:32:38,758 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:32:38,758 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:32:38,758 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:32:38,758 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:32:38,758 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:32:38,804 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:32:38,804 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:32:38,804 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:32:38,804 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:32:39,759 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:32:39,759 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:32:40,489 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:32:40,492 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:32:40,492 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]3995
2023-04-17T21:32:40,492 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:32:40,492 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:32:40,492 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STOPPED -> WORKER_STARTED
2023-04-17T21:32:40,492 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:32:40,492 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:32:40,492 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:32:40,493 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781560493
2023-04-17T21:32:40,493 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:32:40,493 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781560493
2023-04-17T21:32:40,502 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:32:42,586 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', '__pycache__', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:32:42,587 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:32:42,587 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from ./server/cp/SiamMask_DAVIS.pth
2023-04-17T21:32:42,586 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:32:42,586-rk0-load_helper.py# 31] load pretrained model from ./server/cp/SiamMask_DAVIS.pth
2023-04-17T21:32:43,750 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:32:43,750-rk0-load_helper.py# 25] remove prefix 'module.'
2023-04-17T21:32:43,750 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - remove prefix 'module.'
2023-04-17T21:32:43,751 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:32:43,751-rk0-load_helper.py# 18] used keys:356
2023-04-17T21:32:43,751 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - used keys:356
2023-04-17T21:32:43,791 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Backend worker process died.
2023-04-17T21:32:43,792 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Traceback (most recent call last):
2023-04-17T21:32:43,792 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in <module>
2023-04-17T21:32:43,792 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     worker.run_server()
2023-04-17T21:32:43,792 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in run_server
2023-04-17T21:32:43,792 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2023-04-17T21:32:43,793 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 154, in handle_connection
2023-04-17T21:32:43,793 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2023-04-17T21:32:43,793 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:32:43,793 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py", line 118, in load_model
2023-04-17T21:32:43,793 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2023-04-17T21:32:43,793 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     service = model_loader.load(
2023-04-17T21:32:43,793 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:32:43,793 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2023-04-17T21:32:43,793 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/site-packages/ts/model_loader.py", line 135, in load
2023-04-17T21:32:43,793 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     initialize_fn(service.context)
2023-04-17T21:32:43,793 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/29c91633e1c64db295e334a5f8508734/tshandler.py", line 51, in initialize
2023-04-17T21:32:43,793 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     model, size = setup(args)
2023-04-17T21:32:43,794 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:32:43,794 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.BatchAggregator - Load model failed: inpaint, error: Worker died.
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/tmp/models/29c91633e1c64db295e334a5f8508734/server/E2FGVI/test.py", line 133, in setup
2023-04-17T21:32:43,794 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:32:43,794 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_STOPPED
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     net = importlib.import_module('model.' + args.model)
2023-04-17T21:32:43,794 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -   File "/home/vish/miniconda3/lib/python3.9/importlib/__init__.py", line 127, in import_module
2023-04-17T21:32:43,794 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stderr
2023-04-17T21:32:43,794 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:32:43,794 [WARN ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-inpaint_1-stdout
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2023-04-17T21:32:43,794 [INFO ] W-9000-inpaint_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stdout
2023-04-17T21:32:43,838 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:32:43,838 [INFO ] W-9000-inpaint_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-inpaint_1-stderr
2023-04-17T21:35:14,899 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:35:14,899 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2023-04-17T21:35:15,016 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:35:15,016 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.7.1
TS Home: /home/vish/miniconda3/lib/python3.9/site-packages
Current directory: /home/vish/projects/deep-video-inpainting-server/server
Temp directory: /tmp
Metrics config path: /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 1
Number of CPUs: 16
Max heap size: 6404 M
Python executable: /home/vish/miniconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/vish/projects/deep-video-inpainting-server/server
Initial Models: inpaint.mar
Log dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Metrics dir: /home/vish/projects/deep-video-inpainting-server/server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/vish/projects/deep-video-inpainting-server/server
Model config: N/A
2023-04-17T21:35:15,019 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:35:15,019 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2023-04-17T21:35:15,030 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:35:15,030 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: inpaint.mar
2023-04-17T21:35:16,067 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:35:16,067 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1 for model inpaint
2023-04-17T21:35:16,067 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:35:16,067 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1 for model inpaint
2023-04-17T21:35:16,068 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:35:16,068 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model inpaint loaded.
2023-04-17T21:35:16,068 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:35:16,068 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: inpaint, count: 1
2023-04-17T21:35:16,072 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:35:16,072 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/vish/miniconda3/bin/python, /home/vish/miniconda3/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /tmp/.ts.sock.9000, --metrics-config, /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2023-04-17T21:35:16,072 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:35:16,072 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2023-04-17T21:35:16,106 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:35:16,106 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2023-04-17T21:35:16,107 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:35:16,107 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2023-04-17T21:35:16,107 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:35:16,107 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2023-04-17T21:35:16,108 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:35:16,108 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2023-04-17T21:35:16,108 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:35:16,108 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2023-04-17T21:35:16,298 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:35:16,298 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2023-04-17T21:35:16,707 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,708 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.65170669555664|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,708 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.51515579223633|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,708 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:38.8|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,708 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:63.037109375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,708 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1291|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,709 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,709 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:21614.65234375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,709 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3581.58203125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,709 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:15.6|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781716
2023-04-17T21:35:16,863 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Listening on port: /tmp/.ts.sock.9000
2023-04-17T21:35:16,865 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Successfully loaded /home/vish/miniconda3/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2023-04-17T21:35:16,865 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - [PID]21470
2023-04-17T21:35:16,865 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Torch worker started.
2023-04-17T21:35:16,865 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Python runtime: 3.9.12
2023-04-17T21:35:16,865 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:35:16,865 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change null -> WORKER_STARTED
2023-04-17T21:35:16,868 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:35:16,868 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2023-04-17T21:35:16,872 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Connection accepted: /tmp/.ts.sock.9000.
2023-04-17T21:35:16,873 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781716873
2023-04-17T21:35:16,873 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1681781716873
2023-04-17T21:35:16,884 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - model_name: inpaint, batchSize: 1
2023-04-17T21:35:18,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - LISTING DIR:  ['.gitignore', 'mask.py', 'tshandler.py', 'davis.py', 'predict.py', '.dockerignore', 'image', 'lib', 'demo_retarget.py', 'cp', 'model.py', 'E2FGVI', 'models', 'train_git.py', 'cog.yaml', 'test.py', 'get_mask', 'Dockerfile', 'serverREADME.md', 'requirements.txt', 'install.sh', 'server.py', 'logs', 'inpaint.py']
2023-04-17T21:35:18,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Created a temporary directory at /tmp/tmp0t3izpmr
2023-04-17T21:35:18,899 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Writing /tmp/tmp0t3izpmr/_remote_module_non_scriptable.py
2023-04-17T21:35:19,765 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - loading
2023-04-17T21:35:19,765 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained model from ./server/cp/SiamMask_DAVIS.pth
2023-04-17T21:35:19,765 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:35:19,764-rk0-load_helper.py# 31] load pretrained model from ./server/cp/SiamMask_DAVIS.pth
2023-04-17T21:35:21,038 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:35:21,038-rk0-load_helper.py# 25] remove prefix 'module.'
2023-04-17T21:35:21,038 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - remove prefix 'module.'
2023-04-17T21:35:21,039 [WARN ] W-9000-inpaint_1-stderr MODEL_LOG - [2023-04-17 21:35:21,039-rk0-load_helper.py# 18] used keys:356
2023-04-17T21:35:21,039 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - used keys:356
2023-04-17T21:35:21,525 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load pretrained SPyNet...
2023-04-17T21:35:21,525 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - load checkpoint from http path: https://download.openmmlab.com/mmediting/restorers/basicvsr/spynet_20210409-c6c1bd09.pth
2023-04-17T21:35:21,526 [INFO ] W-9000-inpaint_1-stdout MODEL_LOG - Loading model from: ./server/E2FGVI/release_model/E2FGVI-HQ-CVPR22.pth
2023-04-17T21:35:21,529 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4645
2023-04-17T21:35:21,529 [INFO ] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4645
2023-04-17T21:35:21,529 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-17T21:35:21,529 [DEBUG] W-9000-inpaint_1 org.pytorch.serve.wlm.WorkerThread - W-9000-inpaint_1 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2023-04-17T21:35:21,529 [INFO ] W-9000-inpaint_1 TS_METRICS - W-9000-inpaint_1.ms:5459|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781721
2023-04-17T21:35:21,529 [INFO ] W-9000-inpaint_1 TS_METRICS - WorkerThreadTime.ms:11|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781721
2023-04-17T21:36:16,551 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29433059692383|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87253189086914|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,551 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,551 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:88.671875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,552 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1816|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,552 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:2|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20211.08984375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4915.4453125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:36:16,552 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781776
2023-04-17T21:37:16,528 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2943229675293|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87253952026367|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:79.98046875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1638|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20202.69921875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4923.48828125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:37:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781836
2023-04-17T21:38:16,528 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2943229675293|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87253952026367|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:78.02734375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1598|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20205.07421875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4921.11328125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:38:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781896
2023-04-17T21:39:16,526 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:75.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,526 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29431915283203|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87254333496094|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,527 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:82.763671875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,527 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1695|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,527 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,527 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20200.8203125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4925.3671875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:39:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681781956
2023-04-17T21:40:16,543 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,544 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29431533813477|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,544 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.8725471496582|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,544 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,544 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:83.740234375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,544 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1715|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,544 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,545 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20202.2265625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,545 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4923.95703125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:40:16,545 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782016
2023-04-17T21:41:16,541 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,541 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29430770874023|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87255477905273|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:79.541015625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1629|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20188.73046875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4937.44921875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:41:16,542 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782076
2023-04-17T21:42:16,527 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2943000793457|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87256240844727|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:80.615234375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1651|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20175.9921875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4950.1953125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:42:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782136
2023-04-17T21:43:16,530 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29429626464844|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87256622314453|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:78.125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1600|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20171.01171875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4955.17578125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:43:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782196
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29429244995117|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.8725700378418|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:79.00390625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1618|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20172.1796875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4954.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:44:16,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782256
2023-04-17T21:45:16,528 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29429244995117|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.8725700378418|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:78.955078125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1617|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20173.89453125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4952.29296875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:45:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782316
2023-04-17T21:46:16,531 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29429244995117|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.8725700378418|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:80.810546875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1655|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20175.7109375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4950.4765625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:46:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782376
2023-04-17T21:47:16,531 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29428482055664|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87257766723633|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:79.19921875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1622|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:19|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20167.078125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4959.109375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:47:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782436
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29428482055664|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87257766723633|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:78.90625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1616|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:10|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20165.80859375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4960.37890625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:48:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782496
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29428100585938|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.8725814819336|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.072265625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1517|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20168.20703125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4957.98046875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:49:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782556
2023-04-17T21:50:16,532 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942771911621|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87258529663086|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.609375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1528|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20168.16015625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4958.02734375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:50:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782616
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942771911621|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87258529663086|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:73.14453125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1498|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:2|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20164.89453125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4961.28515625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:51:16,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782676
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29427337646484|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87258911132812|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:72.4609375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1484|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:2|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20163.5234375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4962.6640625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:52:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782736
2023-04-17T21:53:16,530 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29426956176758|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87259292602539|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.560546875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1527|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20162.25|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4963.9375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:53:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782796
2023-04-17T21:54:16,534 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942657470703|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87259674072266|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:76.5625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1568|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20158.81640625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4967.36328125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:54:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782856
2023-04-17T21:55:16,534 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942657470703|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87259674072266|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,534 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:81.15234375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1662|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20164.28125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4961.890625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:55:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782916
2023-04-17T21:56:16,527 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942657470703|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87259674072266|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,527 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,527 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:85.009765625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1741|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20160.578125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4965.5859375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:56:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681782976
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29425430297852|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87260818481445|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.658203125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1529|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,528 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20160.828125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4965.33984375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:57:16,529 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783036
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29425430297852|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87260818481445|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.31640625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1522|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:3|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20162.3984375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4963.7890625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:58:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783096
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29425430297852|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87260818481445|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:72.021484375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1475|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20158.94140625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4967.23828125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T21:59:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783156
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:66.7|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29424667358398|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87261581420898|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.0234375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1516|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,524 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20190.96875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,525 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4935.21875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:00:16,525 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783216
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29424667358398|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87261581420898|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:73.2421875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1500|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20195.87109375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4930.26953125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:01:16,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783276
2023-04-17T22:02:16,535 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29424285888672|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87261962890625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:73.73046875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1510|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:2|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20198.89453125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4927.29296875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:02:16,536 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783336
2023-04-17T22:03:16,534 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29424285888672|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87261962890625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.51171875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1526|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20194.15625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4932.0234375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:03:16,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783396
2023-04-17T22:04:16,543 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,543 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29423904418945|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,543 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87262344360352|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,543 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,543 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.12109375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,544 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1518|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,544 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:18|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,544 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20195.14453125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,544 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4931.04296875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:04:16,544 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783456
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942352294922|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87262725830078|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:86.083984375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1763|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20192.99609375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4933.19140625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:05:16,548 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783516
2023-04-17T22:06:16,529 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.2942352294922|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87262725830078|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:78.80859375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1614|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20195.91015625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4930.27734375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:06:16,530 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.1|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783576
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29422760009766|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87263488769531|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:78.955078125|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1617|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20189.42578125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4936.76171875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:07:16,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783636
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29422760009766|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87263488769531|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:74.853515625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1533|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20188.94921875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4937.23046875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:08:16,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783696
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:145.29422760009766|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:92.87263488769531|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUtilization.Percent:79.150390625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUMemoryUsed.Megabytes:1621|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,535 [INFO ] pool-3-thread-1 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,536 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:20189.75390625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,536 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4936.43359375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:09:16,536 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783756
2023-04-17T22:10:16,532 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,533 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:145.29421997070312|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,533 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:92.87264251708984|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,533 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,533 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:77.734375|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,533 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:1592|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,534 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:0|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,534 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20188.41796875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,534 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:4937.76953125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:10:16,534 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783816
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:145.29421997070312|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:92.87264251708984|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:76.66015625|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:1570|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20186.35546875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:4939.83203125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:11:16,533 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783876
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:145.29421997070312|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:92.87264251708984|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:79.248046875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:1623|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:1|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20179.28515625|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,532 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:4946.90234375|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:12:16,533 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783936
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:145.29421615600586|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:92.87264633178711|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:39.0|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUtilization.Percent:86.23046875|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - GPUMemoryUsed.Megabytes:1766|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - GPUUtilization.Percent:3|#Level:Host,device_id:0|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,558 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:20182.9921875|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,559 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:4943.1953125|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
2023-04-17T22:13:16,559 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:21.2|#Level:Host|#hostname:DESKTOP-LU4DJEU,timestamp:1681783996
